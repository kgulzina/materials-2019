<!DOCTYPE html>
<html>
  <head>
    <title>Stat 585 - Reading data from files</title>
    <meta charset="utf-8">
    <meta name="author" content="Heike Hofmann" />
    <link href="01_ascii_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="01_ascii_files/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="default" type="text/css" />
    <link rel="stylesheet" href="default-fonts" type="text/css" />
    <link rel="stylesheet" href="tweaks.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Stat 585 - Reading data from files
### Heike Hofmann

---

class:center,middle


# Reading Data

---
class:inverse-bk,center
## 95 printable characters
&lt;img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/42/ASCII_full.svg/217px-ASCII_full.svg" width = "90%"/&gt;
---

  
## ASCII
  
- short for American  Standard  Code for  Information  Interchange (1960, Bell Data)

- developed from telegraph code (such as Morse code)

- enables text representation on computers, screens and  communication devices

- uses 7-bit binary integers

- encodes 128 specified characters, numbers 0-9, letters a-z, A-Z, some basic punctuation, and (some now obsolete) control codes

---


## ASCII reference card

&lt;img src="https://upload.wikimedia.org/wikipedia/commons/8/82/US-ASCII_code_chart.png" alt="ASCII image" width=650&gt;
  
  
---

## [ASCII](http://en.wikipedia.org/wiki/Ascii)
  
- printable characters: 100 0001=A, 100 0010=B, 110 0001=a, 110 0010=b, ...

- first 32 chars are for control, e.g. 000 1000=BS=backspace, 111 1111=DEL=delete, 

- horizontal tab (000 1001=HT \t), line feed (000 1010=LF \n) and carriage return (000 1101=CR \r) are also control codes

- Advantage of ASCII: human readable, less prone to error/can be humanly checked



---

## ASCII and R

- base R supports reading ASCII files, e.g. `read.table(), read.csv(), read.delim()` reads data from ASCII files with specified delimiters 

- `write.table()` writes ASCII files

- the `readr` package provides similar functionality: `read_csv, read_tsv, read_delim`

- `readr` functions are faster than base R functions, if the whole file is being read at once

---

## Binary file formats

- No restriction in terms on content, streams of bytes

- Advantage: Generally much smaller files, and with compression even smaller, e.g. `nasadata.csv` is 3.7Mb, `nasadata.rds` is 288kb

- Disadvantage: Can be machine-dependent

---

## Binary files and R

- `saveRDS()` saves a single R object in binary format, use extension `.rds`

- `readRDS()` reads R binary file

- `save()` saves all objects in a binary file (and keeps their names), use extension `.rda` 

- `load()` retrieves these objects (using the same names)

---

## Example


```r
system.time(d1 &lt;- read.csv("../data/nasadata.csv"))
```

```
##    user  system elapsed 
##   0.131   0.012   0.144
```

```r
dim(d1)
```

```
## [1] 41472    14
```

```r
d1[1,]
```

```
##   time y x   lat   long       date cloudhigh cloudlow
## 1    1 1 1 -21.2 -113.8 1995-01-01       0.5       31
##   cloudmid ozone pressure surftemp temperature  id
## 1        2   260     1000    297.4       296.9 1-1
```

---

## Example


```r
system.time(d2 &lt;- readRDS("../data/nasadata.rds"))
```

```
##    user  system elapsed 
##   0.027   0.000   0.026
```

```r
dim(d2)
```

```
## [1] 41472    16
```

```r
d2[1,]
```

```
##   time y x   lat   long       date cloudhigh cloudlow
## 1    1 1 1 -21.2 -113.8 1995-01-01       0.5       31
##   cloudmid ozone pressure surftemp temperature  id month
## 1        2   260     1000    297.4       296.9 1-1     1
##   year
## 1 1995
```

---

## Awkward text formats and R

The National Climate Data Center at NOAA publishes information on temperature and precipation across a network of stations in the US.

The Data can be accessed through ftp at ftp://ftp.ncdc.noaa.gov/pub/data/ushcn/v2.5, a code book with a description of the data structure is available at
ftp://ftp.ncdc.noaa.gov/pub/data/ushcn/v2.5/readme.txt


```r
temp.all&lt;-readLines("../data/USH00132999.raw.tmax", n = 5)
temp.all
```

```
## [1] "USH00132999 1899 -9999    -9999    -9999    -9999    -9999    -9999    -9999    -9999    -9999    -9999    -9999      -62f  "
## [2] "USH00132999 1900 -9999     -427b     482e    1854a    2468     2815     2879b    3151     2416a    2229      563      205   "
## [3] "USH00132999 1901   222a    -191      646     1673     2337     2909     3624     3137     2444     1887      863     -160   "
## [4] "USH00132999 1902    77     -262     1026a    1636     2434     2584h    2895a    2620     2231a   -9999    -9999    -9999   "
## [5] "USH00132999 1903 -9999     -128b   -9999    -9999     2117d    2289b    2687f    2582     2266f    1834a     648       -7   "
```

---

## From the code book

```
2.2.1 DATA FORMAT

Variable          Columns      Type
--------          -------      ----
  
ID                 1-11        Integer
YEAR              13-16        Integer
VALUE1            17-22        Integer
DMFLAG1           23-23        Character
QCFLAG1           24-24        Character
DSFLAG1           25-25        Character
.                 .             .
.                 .             .
.                 .             .
VALUE12          116-121       Integer
DMFLAG12         122-122       Character
QCFLAG12         123-123       Character
DSFLAG12         124-124       Character
```

---

## Fixed width format

- Fixed formats can be read with `read.fwf()` or `readr::read_fwf()`

- Need to specify column positions: pretty painful to specify


```r
library(tidyverse)
temps &lt;- read_fwf("../data/USH00132999.raw.tmax",
                  col_positions = fwf_positions(
                    start=c( 1,13, rep(16+9*0:11, each=4) + c(1,7,8,9)), 
                    end  =c(11,16, rep(16+9*0:11, each=4) + c(6,7,8,9))))
names(temps) &lt;- c("Station", "Year", 
                  paste0(rep(c("Value","DMflag", "QCflag", "DSflag"), 12), 
                         rep(1:12, each=4)))
```

---

## 


```r
FortDodge &lt;- temps %&gt;% 
  gather(key="Month", value="Temp_Max", starts_with("Value"))
FortDodge$Month &lt;- as.numeric(gsub("Value", "", FortDodge$Month))
FortDodge$Temp_Max &lt;- replace(FortDodge$Temp_Max, 
                              FortDodge$Temp_Max == -9999, NA)

FortDodge %&gt;% ggplot(aes(x = Year, Temp_Max/100)) + 
  geom_point() + facet_wrap(~Month, nrow=2) 
```

![](01_ascii_files/figure-html/unnamed-chunk-5-1.png)&lt;!-- --&gt;

---

## Your turn (10 min)

The file `ushcn-v2.5-stations.txt` contains information on all weather stations in the USHCN network. This file is also in fixed width format.
**Read the file into R and plot latitude versus longitude.**
  
```
----------------------------------------
Variable             Columns    Type
----------------------------------------
COUNTRY CODE             1-2    Character
NETWORK CODE               3    Character
ID PLACEHOLDERS ("00")   4-5    Character
COOP ID                 6-11    Character
LATITUDE               13-20    Real
LONGITUDE              22-30    Real
ELEVATION              33-37    Real
STATE                  39-40    Character
NAME                   42-71    Character
COMPONENT 1 (COOP ID)  73-78    Character
COMPONENT 2 (COOP ID)  80-85    Character
COMPONENT 3 (COOP ID)  87-92    Character
UTC OFFSET             94-95    Integer
-----------------------------------------
```

---

## HTML FILES 

- A lot of data is available online in the form of html tables

- Extracting the data requires recognizing the html table format, and stripping off the html

- Packages such as `xml`, `rvest`, ... helps with this

---

## HTML FILES 

Pulling election results off the web...


```r
library(rvest)
url &lt;- "http://www.nytimes.com/elections/results/iowa"
doc &lt;- read_html(url)
tables &lt;- html_table(doc, fill=TRUE)
head(tables[[2]])
```

```
##   Vote by county  Trump Clinton
## 1           Polk 93,492 119,804
## 2           Linn 48,390  58,935
## 3          Scott 39,149  40,440
## 4        Johnson 21,044  50,200
## 5     Black Hawk 27,476  32,233
## 6          Story 19,458  25,709
```

---

## Other binary formats and R

- Packages `foreign` or `haven`: Data export/import for other (statistical) software: Stata, Epi, Octave, SPSS, Systat, SAS

- Package `openxlsx` or `readxl` import/export with Excel spreadsheets
e.g. web index data at http://www.visualizing.org/datasets/web-index-2013



```r
library(foreign)
knights &lt;- read.spss("../data/knightfoundation2008sotcdata.por")
str(knights)
```

---

## JSON

- JSON is short for JavaScript  Object Notation (http://json.org/) 

- it is a popular lightweight data interchange format

- Human readable and writable

- Utilized by many web APIs, e.g. tumblr, twitter, ... 

- ... and also the Census Bureau!
  
e.g. result from get query in JSON format:
  
```
[["P0010001","NAME","state"],
 ["710231","Alaska","02"],
 ["4779736","Alabama","01"],
 ["2915918","Arkansas","05"],
 ["6392017","Arizona","04"],
 ["37253956","California","06"]]
```

i.e. vector of vector format - focus is on individual rows in a data set, whereas R puts emphasis on individual columns (data set is list of vectors).


---

## Example: Census Bureau API



```r
library(devtools)
if (!require(cbapi)) {
  install_github("heike/cbapi") # run this the first time 
  library(cbapi)
}
setkey("7f784587c3918611ad6ca67188d9b269b3558dd4") # my key - 
```

```
## key is saved, now you will be able to access data through the API.
```

```r
#                     if you want to use this, get your own :)

# population based on 2010 Census:
popstate &lt;- read.census(sprintf("http://api.census.gov/data/2010/sf1?key=%s&amp;get=P0010001,NAME&amp;for=state:*", getkey()))
head(popstate)
```

```
##   P0010001       NAME state
## 1  4779736    Alabama    01
## 2   710231     Alaska    02
## 3  6392017    Arizona    04
## 4  2915918   Arkansas    05
## 5 37253956 California    06
## 6  5029196   Colorado    08
```

---

## Why do we need to access all these formats? 

- To solve a problem, may need to collate data from multiple sources

- Rearranging and merging data from different sources helps to pull together the data necessary to solve the problem

---

## Reading and blog

Watch the talk Prof Donald Knuth gave at the useR!2016. Based on that, answer the following questions:
  
  - What role does literate programming play in your life so far?

  - Where do you see potential in applying literate programming in your workflow?
  
Make a blog entry by &lt;!-- TODO: Add date --&gt;
    </textarea>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create();
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function() {
  var d = document, s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})();</script>

<script>
(function() {
  var i, text, code, codes = document.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
})();
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
